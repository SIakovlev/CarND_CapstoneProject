
(carnd-advdl-odlab) C:\Users\UK000044\git\CarND_CapstoneProject\training>python main.py
TensorFlow Version: 1.4.0
2018-07-21 06:53:01.461777: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\platform\cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2
2018-07-21 06:53:01.759140: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1030] Found device 0 with properties:
name: Quadro P3000 major: 6 minor: 1 memoryClockRate(GHz): 1.215
pciBusID: 0000:01:00.0
totalMemory: 6.00GiB freeMemory: 4.97GiB
2018-07-21 06:53:01.765569: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Quadro P3000, pci bus id: 0000:01:00.0, compute capability: 6.1)
2018-07-21 06:53:02.063407: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Quadro P3000, pci bus id: 0000:01:00.0, compute capability: 6.1)
Default GPU Device: /device:GPU:0
2018-07-21 06:53:02.080929: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Quadro P3000, pci bus id: 0000:01:00.0, compute capability: 6.1)
Selected 101 total images (76 for training, propn=0.750000)
[<tf.Variable 'conv1_1/filter:0' shape=(3, 3, 3, 64) dtype=float32_ref>, <tf.Variable 'conv1_1/biases:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'conv1_2/filter:0' shape=(3, 3, 64, 64) dtype=float32_ref>, <tf.Variable 'conv1_2/biases:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'conv2_1/filter:0' shape=(3, 3, 64, 128) dtype=float32_ref>, <tf.Variable 'conv2_1/biases:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'conv2_2/filter:0' shape=(3, 3, 128, 128) dtype=float32_ref>, <tf.Variable 'conv2_2/biases:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'conv3_1/filter:0' shape=(3, 3, 128, 256) dtype=float32_ref>, <tf.Variable 'conv3_1/biases:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'conv3_2/filter:0' shape=(3, 3, 256, 256) dtype=float32_ref>, <tf.Variable 'conv3_2/biases:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'conv3_3/filter:0' shape=(3, 3, 256, 256) dtype=float32_ref>, <tf.Variable 'conv3_3/biases:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'conv4_1/filter:0' shape=(3, 3, 256, 512) dtype=float32_ref>, <tf.Variable 'conv4_1/biases:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'conv4_2/filter:0' shape=(3, 3, 512, 512) dtype=float32_ref>, <tf.Variable 'conv4_2/biases:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'conv4_3/filter:0' shape=(3, 3, 512, 512) dtype=float32_ref>, <tf.Variable 'conv4_3/biases:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'conv5_1/filter:0' shape=(3, 3, 512, 512) dtype=float32_ref>, <tf.Variable 'conv5_1/biases:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'conv5_2/filter:0' shape=(3, 3, 512, 512) dtype=float32_ref>, <tf.Variable 'conv5_2/biases:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'conv5_3/filter:0' shape=(3, 3, 512, 512) dtype=float32_ref>, <tf.Variable 'conv5_3/biases:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'fc6/weights:0' shape=(7, 7, 512, 4096) dtype=float32_ref>, <tf.Variable 'fc6/biases:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'fc7/weights:0' shape=(1, 1, 4096, 4096) dtype=float32_ref>, <tf.Variable 'fc7/biases:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'dense_cw/kernel:0' shape=(442368, 32) dtype=float32_ref>, <tf.Variable 'dense_cw/bias:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'final_layer_cw/kernel:0' shape=(32, 4) dtype=float32_ref>, <tf.Variable 'final_layer_cw/bias:0' shape=(4,) dtype=float32_ref>]
2018-07-21 06:53:32.016852: W C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\bfc_allocator.cc:217] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.14GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
2018-07-21 06:53:32.596130: W C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\bfc_allocator.cc:217] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.14GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
2018-07-21 06:53:32.635095: W C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\bfc_allocator.cc:217] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.13GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
............................................................................
Epoch: 0 Loss/batch: 84.14290654493897 time so far: 0:00:35.267239............................................................................
Epoch: 1 Loss/batch: 1.4040542135113163 time so far: 0:01:08.024989............................................................................
Epoch: 2 Loss/batch: 1.3742396941310482 time so far: 0:01:40.762691............................................................................
Epoch: 3 Loss/batch: 1.368306222714876 time so far: 0:02:13.535481............................................................................
Epoch: 4 Loss/batch: 1.3627553566506034 time so far: 0:02:46.243107............................................................................
Epoch: 5 Loss/batch: 1.3576031688012575 time so far: 0:03:18.987803............................................................................
Epoch: 6 Loss/batch: 1.3528412251096023 time so far: 0:03:51.728520............................................................................
Epoch: 7 Loss/batch: 1.348451526541459 time so far: 0:04:24.482290............................................................................
Epoch: 8 Loss/batch: 1.3444122923047919 time so far: 0:04:57.272128............................................................................
Epoch: 9 Loss/batch: 1.3407004569706165 time so far: 0:05:30.009860............................................................................
Epoch: 10 Loss/batch: 1.3372929253076251 time so far: 0:06:02.747105............................................................................
Epoch: 11 Loss/batch: 1.3341672749895799 time so far: 0:06:35.569025............................................................................
Epoch: 12 Loss/batch: 1.3313020452072746 time so far: 0:07:08.287263............................................................................
Epoch: 13 Loss/batch: 1.3286769295993603 time so far: 0:07:40.955772............................................................................
Epoch: 14 Loss/batch: 1.3262728640907688 time so far: 0:08:13.570139............................................................................
Epoch: 15 Loss/batch: 1.324072069243381 time so far: 0:08:46.208570............................................................................
Epoch: 16 Loss/batch: 1.3220579655546891 time so far: 0:09:18.879114............................................................................
Epoch: 17 Loss/batch: 1.3202151452240192 time so far: 0:09:51.549624............................................................................
Epoch: 18 Loss/batch: 1.3185294333257174 time so far: 0:10:24.249193............................................................................
Epoch: 19 Loss/batch: 1.3169876242938794 time so far: 0:10:56.950793
Training Finished. Saving test images to: ./runs\1532153067.4251
Test set complete, 8 of 25 correct (proportion=0.320000)


(carnd-advdl-odlab) C:\Users\UK000044\git\CarND_CapstoneProject\training>